# Required connection configs for Kafka producer, consumer, and admin
#Add your host here. Alter the port if needed
bootstrap.servers=<bootstrap-server-host>:<port>
security.protocol=SASL_SSL

# Use the api key and secret created in confluent cloud here as username and password
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<api-key>' password='<secret>';
sasl.mechanism=PLAIN

# Required for correctness in Apache Kafka clients prior to 2.6
client.dns.lookup=use_all_dns_ips

# Best practice for higher availability in Apache Kafka clients prior to 3.0
session.timeout.ms=45000

# Best practice for Kafka producer to prevent data loss
acks=all

# Serializers for producer
key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=io.confluent.kafka.serializers.json.KafkaJsonSchemaSerializer

# Deserializers for consumer
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=io.confluent.kafka.serializers.json.KafkaJsonSchemaDeserializer

# Required connection configs for Confluent Cloud Schema Registry
# Sample Url => https://psrc.aws.confluent.cloud
schema.registry.url=<schema-registry-url>
basic.auth.credentials.source=USER_INFO
basic.auth.customer.info=<sr-api-key>:<sr-secret>